{
  "enclosure_url": "https://media.transistor.fm/6bc0689d/ffdb90a9.mp3",
  "episode_id": "5c6bd52e3a004413b0529c9ea7b346f72c229890ab5a08caff7003f2fd491082",
  "feed_id": "Practical AI Podcast",
  "guid": "changelog.com/7/632",
  "link": "https://share.transistor.fm/s/6bc0689d",
  "published_utc": null,
  "summary": "<p><strong><em>Fully Connected</em></strong><em> – a series where Chris and Daniel keep you up to date with everything that’s happening in the AI community.</em></p><p>This week we discuss BERT, a new method of pre-training language representations from Google for natural language processing (NLP) tasks. Then we tackle Facebook’s Horizon, the first open source reinforcement learning platform for large-scale products and services. We also address synthetic data, and suggest a few learning resources.</p><p><br /></p><p>Sponsors:</p><ul><li><a href=\"https://www.fastly.com/?utm_source=changelog&amp;utm_medium=podcast&amp;utm_campaign=changelog-sponsorship\">Fastly</a> – <strong>Our bandwidth partner.</strong> Fastly powers fast, secure, and scalable digital experiences. Move beyond your content delivery network to their powerful edge cloud platform. Learn more at <a href=\"https://www.fastly.com/?utm_source=changelog&amp;utm_medium=podcast&amp;utm_campaign=changelog-sponsorship\">fastly.com</a>. </li><li><a href=\"https://rollbar.com/changelog\">Rollbar</a> – <strong>We catch our errors before our users do because of Rollbar.</strong> Resolve errors in minutes, and deploy your code with confidence. Learn more at <a href=\"https://rollbar.com/changelog\">rollbar.com/changelog</a>. </li><li><a href=\"https://linode.com/changelog\">Linode</a> – <strong>Our cloud server of choice.</strong> Deploy a fast, efficient, native SSD cloud server for only $5/month. Get 4 months free using the code changelog2018. Start your server - head to <a href=\"https://linode.com/changelog\">linode.com/changelog</a></li><li><a href=\"https://www.algolia.com/?utm_source=changelog&amp;utm_medium=podcast&amp;utm_campaign=changelog-sponsorship\">Algolia</a> – <strong>Our search partner.</strong> Algolia’s full suite search APIs enable teams to develop unique search and discovery experiences across all platforms and devices. We’re using Algolia to power our site search here at Changelog.com. Get started for free and learn more at <a href=\"https://www.algolia.com/?utm_source=changelog&amp;utm_medium=podcast&amp;utm_campaign=changelog-sponsorship\">algolia.com</a>. </li></ul><p>Featuring:</p><ul><li>Chris Benson – <a href=\"https://chrisbenson.com\">Website</a>, <a href=\"https://github.com/chrisbenson\">GitHub</a>, <a href=\"https://www.linkedin.com/in/chrisbenson\">LinkedIn</a>, <a href=\"https://x.com/chrisbenson\">X</a></li><li>Daniel Whitenack – <a href=\"https://www.datadan.io/\">Website</a>, <a href=\"https://github.com/dwhitena\">GitHub</a>, <a href=\"https://x.com/dwhitena\">X</a></li></ul><p>Show Notes:</p><p>News/Discussion:</p><ul><li><a href=\"https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx\">Is artificial intelligence set to become art’s next medium?</a></li><li>BERT (a new method for obtaining rich contextual language representations during pre-training): <ul><li><a href=\"https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html\">Google research article</a></li><li><a href=\"https://github.com/google-research/bert\">TensorFlow BERT</a></li><li><a href=\"https://arxiv.org/abs/1810.04805\">BERT paper</a></li><li><a href=\"https://github.com/huggingface/pytorch-pretrained-BERT\">PyTorch BERT</a></li><li><a href=\"https://www.nytimes.com/2018/11/18/technology/artificial-intelligence-language.html\">NY Times article</a></li><li><a href=\"https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\">Example Colab notebook</a></li><li><a href=\"https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\">BERT explained article</a></li><li><a href=\"https://arxiv.org/pdf/1706.03762.pdf\">Transformer paper</a></li><li><a href=\"https://towardsdatascience.com/google-open-sources-bert-to-train-natural-language-models-without-breaking-the-bank-813ef38018fc\">Google Open Sources BERT to Train Natural Language Models Without Breaking the Bank</a></li></ul></li><li><a href=\"https://code.fb.com/ml-applications/horizon\">Horizon: The first open source reinforcement learning platform for large-scale products and services</a></li><li><a href=\"https://www.7wdata.be/business-leadership/does-synthetic-data-hold-the-secret-to-artificial-intelligence\">Does Synthetic Data Hold The Secret To Artificial Intelligence?</a></li><li><a href=\"https://blogs.thomsonreuters.com/answerson/moving-forward-with-ai-likely-a-series-of-small-steps-not-giant-leaps\">AI Experts: Moving forward with AI likely a series of small steps, not giant leaps</a></li></ul><p>Learning resources:</p><ul><li><a href=\"https://medium.com/@nathaliejeans7/the-backpropagation-algorithm-demystified-41b705229727\">The Backpropagation Algorithm Demystified</a></li></ul><p>Books</p><ul><li><a href=\"https://github.com/iamtrask/Grokking-Deep-Learning\">“Grokking Deep Learning” by Andrew Trask</a></li></ul><p>Upcoming Events: </p><ul><li>Register for <a href=\"https://practicalai.fm/webinars\">upcoming webinars here</a>!</li></ul>",
  "title": "BERT: one NLP model to rule them all"
}
